{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Attention_exercise.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGC7hu_9mnWf",
        "colab_type": "text"
      },
      "source": [
        "# Week 13 Exercise - Transformers\n",
        "\n",
        "In this notebook, we will explore the creation of a Transformer Network for English to French translation.  Note that **Transformers are resource intensive and hard to train.** You will want to run these notebooks on a machine equipped with a GPU or on [Google Colab](http://colab.research.google.com).\n",
        "\n",
        "To begin, let's import a corpus of paired English and French text.  Additionally, we'll tokenize the words (i.e. create a dictionary for each vocabulary associating every word with an integer index).  There is no need to modify this cell, but have a look at what is contained in fr_to_ix (for example) and in enlines.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKXpuCUvmpGp",
        "colab_type": "code",
        "outputId": "e8f852e7-d3cb-4b93-af2a-3f9c6c77bc78",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import files\n",
        "src = list(files.upload().values())[0]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-74827a3f-ea67-4e8e-b45b-d605105a2f2a\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-74827a3f-ea67-4e8e-b45b-d605105a2f2a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving english.txt to english.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSYfRIofnmh9",
        "colab_type": "code",
        "outputId": "f70b3074-c369-40fc-adc5-3b8ccd137873",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import files\n",
        "src = list(files.upload().values())[0]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b5707204-bf5d-4cce-8f45-31ad64c724eb\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-b5707204-bf5d-4cce-8f45-31ad64c724eb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving french.txt to french.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmqX6-gun5jC",
        "colab_type": "code",
        "outputId": "af708d95-b0ce-484f-8116-25dab40a6426",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os \n",
        "os.listdir()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'french.txt', 'english.txt', 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MwqexnkmnWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import math\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if torch.cuda.is_available():  \n",
        "    device = \"cuda:0\" \n",
        "else:  \n",
        "    device = \"cpu\" \n",
        "\n",
        "with open('./french.txt', encoding=\"utf-8\") as file:\n",
        "    frvocab = file.read().lower()\n",
        "    frvocab = ''.join([i if ord(i) < 128 else ' ' for i in frvocab])\n",
        "    frlines = frvocab.split('\\n')\n",
        "frlines = [re.sub(r'[^\\w\\s\\']','',i).split() for i in frlines]\n",
        "frvocab = set(re.sub(r'[^\\w\\s\\']','',frvocab).replace('\\n',' ').split(' '))\n",
        "\n",
        "with open('./english.txt', encoding=\"utf-8\") as file:\n",
        "    envocab = file.read().lower()\n",
        "    envocab = ''.join([i if ord(i) < 128 else '' for i in envocab])\n",
        "    enlines = envocab.split('\\n')\n",
        "enlines = [re.sub(r'[^\\w\\s]','',i).split() for i in enlines]\n",
        "envocab = set(re.sub(r'[^\\w\\s]','',envocab).replace('\\n',' ').strip().split(' '))\n",
        "envocab.add('<pad>')\n",
        "envocab.add('<start>')\n",
        "envocab.add('<eos>')\n",
        "frvocab.add('<pad>')\n",
        "frvocab.add('<start>')\n",
        "frvocab.add('<eos>')\n",
        "fr_to_ix = {word: i for i, word in enumerate(frvocab)}\n",
        "en_to_ix = {word: i for i, word in enumerate(envocab)}\n",
        "ix_to_fr = {fr_to_ix[word]:word for word in frvocab}\n",
        "ix_to_en = {en_to_ix[word]:word for word in envocab}\n",
        "enmax = 0\n",
        "frmax = 16\n",
        "\n",
        "for i,w in enumerate(enlines):\n",
        "    temp = len(w)\n",
        "    if temp > enmax:\n",
        "        enmax = temp\n",
        "\n",
        "for i,w in enumerate(frlines):\n",
        "    temp = len(w)\n",
        "    if temp > frmax:\n",
        "        frmax = temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8VIjeB2mnWj",
        "colab_type": "text"
      },
      "source": [
        "Next we'll create a handful of helper functions that do things like\n",
        " - Tokenize an english string, run it through the transformer producing predictions, then convert back to a french string\n",
        " - Compare predicted and target output\n",
        " - Mask a string\n",
        " - Load paired english/french sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMimt9IZmnWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "    # Read in an english string\n",
        "    line = re.sub(r'[^\\w\\s]','',sentence).split()\n",
        "    # tokenize/pad for consistent sequence length\n",
        "    line = F.pad(torch.tensor([en_to_ix[w.lower()] for w in line]),(0,enmax-len(line)),value = en_to_ix['<pad>']).unsqueeze(0).to(device)\n",
        "    # Create an array to hold the French sentence\n",
        "    target = torch.Tensor(1,frmax-1)\n",
        "    target = target.new_full((1,frmax-1),fr_to_ix['<pad>']).long().to(device)\n",
        "    # Start sentence with a <start> character\n",
        "    target[0,0] = fr_to_ix['<start>']\n",
        "    \n",
        "    src,trg = mask(line,target)\n",
        "    encoding = model.encode(line,src)\n",
        "    K,V = model.create_dec_KV(encoding)\n",
        "    for i in range(1,frmax-1):\n",
        "        test2 = model.decode(target,K,V,src,trg)\n",
        "        lastout = test2[0,i-1].argmax()\n",
        "        if lastout.item() == fr_to_ix['<eos>']:\n",
        "            break\n",
        "        target[0,i] = lastout\n",
        "        src,trg = mask(line,target)\n",
        "    translation = test2.argmax(2).squeeze(0)\n",
        "    translation_string = ''\n",
        "    for w in translation:\n",
        "        if ix_to_fr[w.item()] == '<eos>':\n",
        "            break\n",
        "        translation_string += ix_to_fr[w.item()] + ' '\n",
        "    return translation_string.strip()\n",
        "\n",
        "def compareoutput(preds,targetlist,loc=None):\n",
        "    # Compare model predictions with true translation\n",
        "    if loc is None:\n",
        "        loc = np.random.randint(len(preds))\n",
        "    predstr = ''\n",
        "    labelstr = ''\n",
        "    for i in range(len(preds[loc][0])):\n",
        "        if ix_to_fr[targetlist[loc][i+1].item()] == '<eos>':\n",
        "            break\n",
        "        predstr += ' '+ ix_to_fr[preds[loc][0][i].item()]\n",
        "        labelstr += ' ' + ix_to_fr[targetlist[loc][i+1].item()]\n",
        "    print(\"\\tOutput:\", predstr)\n",
        "    print(\"\\tTarget:\",labelstr)\n",
        "    \n",
        "class PositionalEncoder(nn.Module):\n",
        "    # Create a positional encoding generator\n",
        "    def __init__(self, d_model, max_seq_len = 58):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        \n",
        "        # create constant 'pe' matrix with values dependant on \n",
        "        # pos and i\n",
        "        pe = torch.zeros(max_seq_len, d_model)\n",
        "        for pos in range(max_seq_len):\n",
        "            for i in range(0, d_model, 2):\n",
        "                pe[pos, i] = \\\n",
        "                math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
        "            for i in range(1,d_model,2):\n",
        "                pe[pos, i] = \\\n",
        "                math.cos(pos / (10000 ** ((2 * i)/d_model)))\n",
        "                \n",
        "        pe = pe\n",
        "        self.register_buffer('pe', pe)\n",
        " \n",
        "    \n",
        "    def forward(self, x):\n",
        "        # make embeddings relatively larger\n",
        "        x = x * math.sqrt(self.d_model)\n",
        "        #add constant to embedding\n",
        "        seq_len = x.size(1)\n",
        "        x = x + Variable(self.pe[:seq_len], \\\n",
        "        requires_grad=False).to(device)\n",
        "        return x\n",
        "\n",
        "def mask(input_seq,target_seq):\n",
        "    input_msk = (input_seq != en_to_ix['<pad>']).unsqueeze(1)\n",
        "    target_msk = (target_seq != fr_to_ix['<pad>']).unsqueeze(1)\n",
        "    size = target_seq.size(1) # get seq_len for matrix\n",
        "    nopeak_mask = np.triu(np.ones((1, size, size)),k=1)\n",
        "    nopeak_mask = Variable(torch.from_numpy(nopeak_mask).to(device) == 0)\n",
        "    target_msk = target_msk & nopeak_mask\n",
        "    return input_msk,target_msk\n",
        "\n",
        "class custdata(Dataset):\n",
        "    # Create a custom dataset object to serve up paired english and french lines\n",
        "    def __init__(self,enlines,frlines):\n",
        "        self.data_len = len(enlines) \n",
        "        self.data = [F.pad(torch.tensor([en_to_ix[w] for w in line]),(0,enmax-len(line)),value = en_to_ix['<pad>']).to(device) for line in enlines]\n",
        "        self.labels = []\n",
        "        for line in frlines:\n",
        "            line = ['<start>',*line,'<eos>']\n",
        "            self.labels.append(F.pad(torch.tensor([fr_to_ix[w] for w in line]),(0,frmax-len(line)),value = fr_to_ix['<pad>']).to(device))\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        return self.data[i],self.labels[i]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f8YCCodmnWn",
        "colab_type": "text"
      },
      "source": [
        "# Attention\n",
        "The first task is to code a self-attention mechanism, which corresponds to implementing Eq. 1 in Vaswani.\n",
        "#### http://jalammar.github.io/illustrated-transformer/ is a great reference for most of the programming in this notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I8fPZEkmnWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class self_attention(nn.Module):\n",
        "    def __init__(self,dim,enc_dim,dropout = .1):\n",
        "        super().__init__()\n",
        "        self.wq = nn.Linear(dim,enc_dim)\n",
        "        self.wk = nn.Linear(dim,enc_dim)\n",
        "        self.wv = nn.Linear(dim,enc_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scaler = np.sqrt(enc_dim)\n",
        "    \n",
        "    def QKV(self,x):\n",
        "        Q = self.wq(x)\n",
        "        K = self.wk(x)\n",
        "        V = self.wv(x)\n",
        "        return Q,K,V\n",
        "    \n",
        "    def score(self,Q,K,V,mask):\n",
        "        # scores are the stuff that goes inside the softmax\n",
        "        scores = Q@K.T.permute(2,0,1)/self.scaler ### TODO ### CALCULATE THE SCORES. !!!DONT TOUCH THE PERMUTE!!!\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        scores = self.dropout(F.softmax(scores,-1)) \n",
        "        return scores@V\n",
        "    \n",
        "    def forward(self,x,mask=None):\n",
        "        Q,K,V = self.QKV(x)\n",
        "        return self.score(Q,K,V,mask)\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ny5exoa4mnWr",
        "colab_type": "text"
      },
      "source": [
        "Next, we need to produce the \"special\" attention mechanism that takes keys and values from the encoder, but queries from the decoder.  This is very similar to the self-attention mechanism, except that there should be two inputs.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUAjr3p1mnWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class encdec_attention(nn.Module):\n",
        "    def __init__(self,dim,dropout = .1):\n",
        "        super().__init__()\n",
        "        self.wq = nn.Linear(dim,dim)\n",
        "        self.wk = nn.Linear(dim,dim)\n",
        "        self.wv = nn.Linear(dim,dim)\n",
        "        self.scaler = np.sqrt(dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def Q(self,x):\n",
        "        return self.wq(x)\n",
        "    \n",
        "    def score(self,Q,K,V,mask):\n",
        "        scores =  Q@K.T.permute(2,0,1)/self.scaler #### TODO #### SAME AS ABOVE\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        scores = self.dropout(F.softmax(scores,-1)) \n",
        "        return scores@V  #### TODO #### SAME AS ABOVE\n",
        "    \n",
        "    def forward(self,x,K,V,mask):\n",
        "        # DB Note: I'm not sure that this signature is right.  Seems like we should be taking x from the\n",
        "        # decoder, as well as another argument (call it y?) from the encoder, then producing K,V,Q internally,\n",
        "        # just like in the self-attention scheme.  Otherwise, how are wk and wv being used here?  it looks like \n",
        "        # these parameters have been shifted over to the Transformer module's create_dec_KV method.\n",
        "        Q = self.Q(x)\n",
        "        out = self.score(Q,K,V,mask)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moO-O98RmnWu",
        "colab_type": "text"
      },
      "source": [
        "# Encoder and Decoder\n",
        "With the attention mechanisms coded, now we need to create encoder and decoder models. These correspond to the things inside the boxes in Figure 1 of Vaswani.  \n",
        "#### Fill in the forward passes of the encoder and decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMTjpQatmnWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class encoder(nn.Module):\n",
        "    def __init__(self,dim,enc_dim,vocab_size,dropout=.1):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.enc_dim = enc_dim\n",
        "        self.residual = nn.Linear(dim,enc_dim)\n",
        "        \n",
        "        self.attention = self_attention(dim,enc_dim,dropout)\n",
        "        self.norm1 = nn.LayerNorm(enc_dim)\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(enc_dim,enc_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.norm2 = nn.LayerNorm(enc_dim)\n",
        "    \n",
        "    def forward(self,x,mask):  #### TODO #### SET UP FORWARD PASS OF ENCODER\n",
        "        shortcut = x\n",
        "        x = self.attention(x)\n",
        "        if self.dim != self.enc_dim: ### DONT TOUCH, THIS IS TO HELP WITH THE RESIDUAL CONNECTION ###\n",
        "            x = self.residual(x)\n",
        "        x = self.norm1(x+shortcut)\n",
        "        shortcut = x\n",
        "        x = self.linear(x)\n",
        "        x = self.norm2(x+shortcut)\n",
        "        return x\n",
        "     \n",
        "        \n",
        "class decoder(nn.Module):\n",
        "    def __init__(self,dim,input_size,vocab_size,dropout=.1):\n",
        "        super().__init__()\n",
        "        self.attention = self_attention(input_size,dim,dropout)\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.EDattention = encdec_attention(dim,dropout)\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(dim,dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.norm3 = nn.LayerNorm(dim)\n",
        "    \n",
        "    def forward(self,x,k,v,enc_mask,dec_mask):#### TODO #### SET UP FORWARD PASS OF DECODER\n",
        "        shortcut = x \n",
        "        x = self.attention(x,dec_mask)\n",
        "        x = self.norm1(x+shortcut)\n",
        "        shortcut = x\n",
        "        x = self.EDattention(x,k,v,enc_mask)\n",
        "        x = x + shortcut\n",
        "        shortcut = x\n",
        "        x = self.linear(x)\n",
        "        return self.norm3(x+shortcut)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CoUQEBLmnWz",
        "colab_type": "text"
      },
      "source": [
        "# Transformer\n",
        "\n",
        "Build the transformer itself by hooking together encoders and decoders.  Note the word embedding layers that we are going to learn.  \n",
        "\n",
        "#### Add encoders and decoders to transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdb026dLmnW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class transformer(nn.Module):\n",
        "    def __init__(self,dim,encoder_dim,enc_vocab_size,dec_vocab_size,input_size):\n",
        "        super().__init__()\n",
        "        self.embedding1 = nn.Embedding(enc_vocab_size,dim)\n",
        "        self.embedding2 = nn.Embedding(dec_vocab_size,encoder_dim)\n",
        "        \n",
        "        self.pe1 = PositionalEncoder(dim,enmax)\n",
        "        self.pe2 = PositionalEncoder(encoder_dim,frmax)\n",
        "        self.encoders = []\n",
        "    \n",
        "        self.encoders.extend([encoder(dim, encoder_dim ,enc_vocab_size) for _ in range(3)]) #### TODO #### ADD DESIRED # OF ENCODERS TO SELF.ENCODERS\n",
        "        \n",
        "        \n",
        "        self.encoders = nn.ModuleList(self.encoders)\n",
        "        \n",
        "        self.decoders = []\n",
        "        \n",
        "        \n",
        "        self.decoders.extend([decoder(encoder_dim, encoder_dim, dec_vocab_size) for _ in range(3)]) #### TODO #### ADD DESIRED # OF DECODERS TO SELF.DECODERS\n",
        "\n",
        "       \n",
        "        self.decoders = nn.ModuleList(self.decoders)\n",
        "        \n",
        "        self.final = nn.Sequential(\n",
        "            nn.Linear(encoder_dim,dec_vocab_size),\n",
        "            nn.LogSoftmax(2)\n",
        "        )\n",
        "        \n",
        "        self.k = nn.Linear(encoder_dim,encoder_dim)\n",
        "        self.v = nn.Linear(encoder_dim,encoder_dim)\n",
        "    def create_dec_KV(self,z):\n",
        "        K = self.k(z)\n",
        "        V = self.v(z)\n",
        "        return K,V\n",
        "    \n",
        "    def encode(self,x,src):\n",
        "        x = self.embedding1(x)\n",
        "        x = self.pe1(x)\n",
        "        for layer in self.encoders:\n",
        "            x = layer(x,src)\n",
        "        return x\n",
        "    \n",
        "    def decode(self,y,K,V,src,trg):\n",
        "        y = self.embedding2(y)\n",
        "        y = self.pe2(y)\n",
        "        for layer in self.decoders:\n",
        "            y = layer(y,K,V,src,trg)\n",
        "        return self.final(y)\n",
        "    \n",
        "    def forward(self,x,y,src,trg):\n",
        "        \n",
        "        x = self.encode(x,src)\n",
        "        K,V = self.create_dec_KV(x)\n",
        "        y = self.decode(y,K,V,src,trg)\n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4jMhq_VmnW3",
        "colab_type": "text"
      },
      "source": [
        "# Train the network.\n",
        "\n",
        "##### This will be slow to train and require a lot of resources. You can reduce the batch_size to lower the vram requirement, you can reduce \n",
        "##### the run time by lowering number_of_lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QjjDpZBmnW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = transformer(enmax,enmax,len(envocab),len(frvocab),frmax)\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep7a1bQ8mnW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.01,weight_decay=.00001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,factor=.1,patience=10,threshold=1,min_lr=.0001)\n",
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ1hZeijmnW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "NUMBER_OF_LINES = 20000\n",
        "\n",
        "train = custdata(enlines[:NUMBER_OF_LINES],frlines[:NUMBER_OF_LINES])\n",
        "trainloader = torch.utils.data.DataLoader(dataset=train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val = custdata(enlines[NUMBER_OF_LINES:NUMBER_OF_LINES+1000],frlines[NUMBER_OF_LINES:NUMBER_OF_LINES+1000])\n",
        "valloader = torch.utils.data.DataLoader(dataset=val, batch_size=1, shuffle=True, drop_last=False)\n",
        "test = custdata(enlines[NUMBER_OF_LINES+1000:NUMBER_OF_LINES+2000],frlines[NUMBER_OF_LINES+1000:NUMBER_OF_LINES+2000])\n",
        "testloader = torch.utils.data.DataLoader(dataset=test, batch_size=1, shuffle=False, drop_last=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDy3P32AmnW_",
        "colab_type": "code",
        "outputId": "9b71774e-3d46-47c9-b41c-61562310973a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(100):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for j,(context, target) in enumerate(trainloader):\n",
        "        trg_input = target[:,:-1]\n",
        "        outmask = target[:,1:]!= fr_to_ix['<pad>']\n",
        "        targets = target[:,1:].contiguous().view(-1)\n",
        "        src,trg = mask(context,trg_input)\n",
        "        output = model(context,trg_input,src,trg)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(output.view(output.shape[0]*output.shape[1],-1),targets)\n",
        "        loss.backward()\n",
        "        total_loss += loss.item()\n",
        "        optimizer.step()\n",
        "    scheduler.step(total_loss)\n",
        "    print('Epoch:', i+1,' loss:', total_loss)\n",
        "    model.eval()\n",
        "    scores = []\n",
        "    preds = []\n",
        "    targetlist = []\n",
        "    for j,(context, target) in enumerate(valloader):\n",
        "            trg_input = target[:,:-1]\n",
        "            targets = target.contiguous().view(-1)\n",
        "            targetlist.append(targets)\n",
        "            src,trg = mask(context,trg_input)\n",
        "            output = model(context,trg_input,src,trg)\n",
        "            pred = F.softmax(output,2).argmax(2)\n",
        "            preds.append(pred)\n",
        "            break\n",
        "    compareoutput(preds,targetlist,loc=0)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  loss: 147.0674066543579\n",
            "\tOutput:  je <eos>\n",
            "\tTarget:  tesvous productif\n",
            "Epoch: 2  loss: 62.72770228981972\n",
            "\tOutput:  je me\n",
            "\tTarget:  doisje tudier\n",
            "Epoch: 3  loss: 48.46027368307114\n",
            "\tOutput:  ne me pas <eos>\n",
            "\tTarget:  ne perdez pas espoir\n",
            "Epoch: 4  loss: 41.26837536692619\n",
            "\tOutput:  il es <eos> <eos> de vous\n",
            "\tTarget:  tu n'auras pas besoin de moi\n",
            "Epoch: 5  loss: 34.86220647394657\n",
            "\tOutput:  vous avez trop trop tard\n",
            "\tTarget:  vous tes venus trop tard\n",
            "Epoch: 6  loss: 29.05304390192032\n",
            "\tOutput:  tu tes s\n",
            "\tTarget:  vous tes beau\n",
            "Epoch: 7  loss: 25.252122327685356\n",
            "\tOutput:  vous la t\n",
            "\tTarget:  aimestu l' t\n",
            "Epoch: 8  loss: 22.82152684777975\n",
            "\tOutput:  vous es respectueux\n",
            "\tTarget:  tu es courageux\n",
            "Epoch: 9  loss: 21.11154491454363\n",
            "\tOutput:  vous tes tr s amusant <pad>\n",
            "\tTarget:  vous tes tr s dr le\n",
            "Epoch: 10  loss: 19.911836341023445\n",
            "\tOutput:  tu le <eos> train terre\n",
            "\tTarget:  c'est toi le ma tre\n",
            "Epoch: 11  loss: 19.217497050762177\n",
            "\tOutput:  vous tes fort dr le\n",
            "\tTarget:  vous tes fort dr le\n",
            "Epoch: 12  loss: 13.01737255603075\n",
            "\tOutput:  vous pouvez tous tous deux\n",
            "\tTarget:  vous pouvez avoir les deux\n",
            "Epoch: 13  loss: 10.598033867776394\n",
            "\tOutput:  peuxtu lire de musique\n",
            "\tTarget:  savezvous lire la musique\n",
            "Epoch: 14  loss: 9.562534507364035\n",
            "\tOutput:  sontils satisfaites\n",
            "\tTarget:  sontelles contentes\n",
            "Epoch: 15  loss: 8.861769646406174\n",
            "\tOutput:  estu seul <eos>\n",
            "\tTarget:  tesvous seul ici\n",
            "Epoch: 16  loss: 8.39987551048398\n",
            "\tOutput:  ne soyez pas si invit ch\n",
            "\tTarget:  ne sois pas si s lective\n",
            "Epoch: 17  loss: 7.98216275125742\n",
            "\tOutput:  il avez besoin de protection <eos> classe\n",
            "\tTarget:  vous avez besoin de points de suture\n",
            "Epoch: 18  loss: 7.674803234636784\n",
            "\tOutput:  vous tes fort timide\n",
            "\tTarget:  vous tes fort timide\n",
            "Epoch: 19  loss: 7.435341265052557\n",
            "\tOutput:  tu avez l'air en\n",
            "\tTarget:  vous avez l'air terrible\n",
            "Epoch: 20  loss: 7.219394471496344\n",
            "\tOutput:  puisje que je peux y aller maintenant\n",
            "\tTarget:  estce que je pourrais y aller maintenant\n",
            "Epoch: 21  loss: 6.996654473245144\n",
            "\tOutput:  pourquoi cette <eos> risque\n",
            "\tTarget:  pourquoi encourir le risque\n",
            "Epoch: 22  loss: 6.835267834365368\n",
            "\tOutput:  vous tes fid ferme\n",
            "\tTarget:  vous tes la chef\n",
            "Epoch: 23  loss: 5.9577704928815365\n",
            "\tOutput:  tesvous acteurs\n",
            "\tTarget:  tesvous inscrit\n",
            "Epoch: 24  loss: 5.809337947517633\n",
            "\tOutput:  qui se ta pendule\n",
            "\tTarget:  qui est cette horloge\n",
            "Epoch: 25  loss: 5.743424007669091\n",
            "\tOutput:  vous es tr s riche\n",
            "\tTarget:  tu es tr s riche\n",
            "Epoch: 26  loss: 5.7057363502681255\n",
            "\tOutput:  qui t'a a envoy e\n",
            "\tTarget:  qui vous a envoy ici\n",
            "Epoch: 27  loss: 5.6505872793495655\n",
            "\tOutput:  peuxtu me pardonner\n",
            "\tTarget:  pouvezvous me pardonner\n",
            "Epoch: 28  loss: 5.627909239381552\n",
            "\tOutput:  te senstu coupable\n",
            "\tTarget:  te senstu coupable\n",
            "Epoch: 29  loss: 5.595686050131917\n",
            "\tOutput:  vous es fort s courageux\n",
            "\tTarget:  tu es tr s courageux\n",
            "Epoch: 30  loss: 5.529508601874113\n",
            "\tOutput:  vous un vous te <eos>\n",
            "\tTarget:  veuxtu que je t'emm ne\n",
            "Epoch: 31  loss: 5.536463478580117\n",
            "\tOutput:  vous tes honte honte\n",
            "\tTarget:  vous tes une honte\n",
            "Epoch: 32  loss: 5.492734448984265\n",
            "\tOutput:  peuxtu me pardonner\n",
            "\tTarget:  pouvezvous me pardonner\n",
            "Epoch: 33  loss: 5.481747539713979\n",
            "\tOutput:  vous tes trop poli\n",
            "\tTarget:  vous tes trop poli\n",
            "Epoch: 34  loss: 5.457221873104572\n",
            "\tOutput:  tu tes tudiant tudiant\n",
            "\tTarget:  vous tes un tudiant\n",
            "Epoch: 35  loss: 5.413876624777913\n",
            "\tOutput:  aimestu des airs\n",
            "\tTarget:  aimezvous les robots\n",
            "Epoch: 36  loss: 5.399038340896368\n",
            "\tOutput:  peuxtu vous faire\n",
            "\tTarget:  pouvezvous le croire\n",
            "Epoch: 37  loss: 5.346799058839679\n",
            "\tOutput:  vous tes trop tard tard\n",
            "\tTarget:  vous tes venue trop tard\n",
            "Epoch: 38  loss: 5.351746041327715\n",
            "\tOutput:  astu v ceci <eos>\n",
            "\tTarget:  astu v rifi ceci\n",
            "Epoch: 39  loss: 5.311470149084926\n",
            "\tOutput:  vous es malpoli toit ferme\n",
            "\tTarget:  tu es le ma tre\n",
            "Epoch: 40  loss: 5.293048124760389\n",
            "\tOutput:  astu vu quelqu'un que tu que\n",
            "\tTarget:  astu vu qui que ce soit\n",
            "Epoch: 41  loss: 5.264971198514104\n",
            "\tOutput:  puisje me un coup\n",
            "\tTarget:  puisje obtenir un remboursement\n",
            "Epoch: 42  loss: 5.256234999746084\n",
            "\tOutput:  tesvous occup aujourd'hui\n",
            "\tTarget:  estu occup aujourd'hui\n",
            "Epoch: 43  loss: 5.247228449210525\n",
            "\tOutput:  pourquoi estu seul\n",
            "\tTarget:  pourquoi tesvous seule\n",
            "Epoch: 44  loss: 5.1891748290508986\n",
            "\tOutput:  y pr tes y\n",
            "\tTarget:  sommesnous pr ts partir\n",
            "Epoch: 45  loss: 5.197932126000524\n",
            "\tOutput:  tu as <eos> <eos>\n",
            "\tTarget:  tu aurais pu mourir\n",
            "Epoch: 46  loss: 5.185855828225613\n",
            "\tOutput:  vous en savez trop\n",
            "\tTarget:  vous en savez trop\n",
            "Epoch: 47  loss: 5.156294768676162\n",
            "\tOutput:  aimestu le sport\n",
            "\tTarget:  aimestu le sport\n",
            "Epoch: 48  loss: 5.0894726775586605\n",
            "\tOutput:  j'en tesvous des coop\n",
            "\tTarget:  vous prenez la visa\n",
            "Epoch: 49  loss: 5.064997786656022\n",
            "\tOutput:  tu tes l mon chemin\n",
            "\tTarget:  vous tes sur mon chemin\n",
            "Epoch: 50  loss: 5.064289206638932\n",
            "\tOutput:  vous es tr timide\n",
            "\tTarget:  tu es fort timide\n",
            "Epoch: 51  loss: 5.018674056977034\n",
            "\tOutput:  pourquoi estu seul\n",
            "\tTarget:  pourquoi tesvous seule\n",
            "Epoch: 52  loss: 5.0038322154432535\n",
            "\tOutput:  tu es la plus e\n",
            "\tTarget:  tu es l'a n e\n",
            "Epoch: 53  loss: 4.980660999193788\n",
            "\tOutput:  aimestu des\n",
            "\tTarget:  aimezvous wagner\n",
            "Epoch: 54  loss: 4.9660195372998714\n",
            "\tOutput:  tu ne <eos> <eos> <eos> moi\n",
            "\tTarget:  tu n'auras pas besoin de moi\n",
            "Epoch: 55  loss: 4.953073604032397\n",
            "\tOutput:  vous tes beau\n",
            "\tTarget:  vous tes beaux\n",
            "Epoch: 56  loss: 4.924616368487477\n",
            "\tOutput:  tesvous en s\n",
            "\tTarget:  tesvous en vacances\n",
            "Epoch: 57  loss: 4.895638033747673\n",
            "\tOutput:  pourquoi astu fait\n",
            "\tTarget:  pourquoi l'avezvous fait\n",
            "Epoch: 58  loss: 4.864337237551808\n",
            "\tOutput:  vous es nouveau la nouveau\n",
            "\tTarget:  tu es nouveau de retour\n",
            "Epoch: 59  loss: 4.85176825709641\n",
            "\tOutput:  ta femme est l\n",
            "\tTarget:  ta femme est ici\n",
            "Epoch: 60  loss: 4.855044698342681\n",
            "\tOutput:  vous tes tr timide\n",
            "\tTarget:  vous tes fort craintives\n",
            "Epoch: 61  loss: 4.805026246234775\n",
            "\tOutput:  vous es d <eos>\n",
            "\tTarget:  tu es surmen e\n",
            "Epoch: 62  loss: 4.803061347454786\n",
            "\tOutput:  tout le monde se calme <eos> s curit\n",
            "\tTarget:  tout le monde se sentit en s curit\n",
            "Epoch: 63  loss: 4.761145466938615\n",
            "\tOutput:  vous es tr s chouette\n",
            "\tTarget:  tu es tr s sympa\n",
            "Epoch: 64  loss: 4.759196834638715\n",
            "\tOutput:  notre ce formulaire\n",
            "\tTarget:  remplis ce formulaire\n",
            "Epoch: 65  loss: 4.728982327505946\n",
            "\tOutput:  n'avezvous pas soif\n",
            "\tTarget:  n'astu pas soif\n",
            "Epoch: 66  loss: 4.716479049995542\n",
            "\tOutput:  vous es tr s timide\n",
            "\tTarget:  tu es tr s timide\n",
            "Epoch: 67  loss: 4.707464961335063\n",
            "\tOutput:  tout le monde devrait y <eos>\n",
            "\tTarget:  tout le monde devrait y aller\n",
            "Epoch: 68  loss: 4.689728127792478\n",
            "\tOutput:  tu n'as pas le choix\n",
            "\tTarget:  tu n'avais pas le choix\n",
            "Epoch: 69  loss: 4.660540280863643\n",
            "\tOutput:  veuxtu te coup la main\n",
            "\tTarget:  veuxtu un coup de main\n",
            "Epoch: 70  loss: 4.657707646489143\n",
            "\tOutput:  ne soyez pas si f\n",
            "\tTarget:  ne sois pas si avare\n",
            "Epoch: 71  loss: 4.647073166444898\n",
            "\tOutput:  tu tes tes <eos>\n",
            "\tTarget:  vous vous exprimez bien\n",
            "Epoch: 72  loss: 4.615645868703723\n",
            "\tOutput:  ne me pas de moi\n",
            "\tTarget:  ne t'approche pas de moi\n",
            "Epoch: 73  loss: 4.588475139811635\n",
            "\tOutput:  connaistu le ais\n",
            "\tTarget:  parlestu fran ais\n",
            "Epoch: 74  loss: 4.595192816108465\n",
            "\tOutput:  vous tes fort s contrari\n",
            "\tTarget:  vous tes tr s contrari\n",
            "Epoch: 75  loss: 4.563471740111709\n",
            "\tOutput:  pourquoi tom a t licenci\n",
            "\tTarget:  pourquoi tom atil t vir\n",
            "Epoch: 76  loss: 4.5660681035369635\n",
            "\tOutput:  tu as manqu le pr\n",
            "\tTarget:  tu as loup une tache\n",
            "Epoch: 77  loss: 4.506250023841858\n",
            "\tOutput:  vous le pinards propri taires\n",
            "\tTarget:  c'est vous les propri taires\n",
            "Epoch: 78  loss: 4.510969921946526\n",
            "\tOutput:  tu comme tu aimes faim\n",
            "\tTarget:  estce que tu aimes moscou\n",
            "Epoch: 79  loss: 4.508324380964041\n",
            "\tOutput:  ne m'oblige pas <eos>\n",
            "\tTarget:  ne m'obligez pas rester\n",
            "Epoch: 80  loss: 4.47696796990931\n",
            "\tOutput:  ton livre est ici\n",
            "\tTarget:  ton livre est ici\n",
            "Epoch: 81  loss: 4.488387703895569\n",
            "\tOutput:  tous sommes sommes toutes lev tes\n",
            "\tTarget:  nous nous sommes tous mis debout\n",
            "Epoch: 82  loss: 4.466539861634374\n",
            "\tOutput:  astu astu de t <eos>\n",
            "\tTarget:  en avezvous bient t fini\n",
            "Epoch: 83  loss: 4.451297082006931\n",
            "\tOutput:  vous tes trop trop tard\n",
            "\tTarget:  vous tes venus trop tard\n",
            "Epoch: 84  loss: 4.41842651180923\n",
            "\tOutput:  tu pouvez ta maintenant\n",
            "\tTarget:  vous pouvez entrer maintenant\n",
            "Epoch: 85  loss: 4.426436450332403\n",
            "\tOutput:  aimestu cie de\n",
            "\tTarget:  appr ciestu wagner\n",
            "Epoch: 86  loss: 4.403799029067159\n",
            "\tOutput:  vous es tr timide\n",
            "\tTarget:  tu es fort craintif\n",
            "Epoch: 87  loss: 4.399994904175401\n",
            "\tOutput:  vous ne m'y <eos> dessus <eos>\n",
            "\tTarget:  tu ne seras pas fusill e\n",
            "Epoch: 88  loss: 4.3766142055392265\n",
            "\tOutput:  vous tes trop maigrichonne\n",
            "\tTarget:  vous tes trop maigrichon\n",
            "Epoch: 89  loss: 4.359932923689485\n",
            "\tOutput:  estu avezvous s r\n",
            "\tTarget:  en estu s re\n",
            "Epoch: 90  loss: 4.363347427919507\n",
            "\tOutput:  vous tes tr s dr\n",
            "\tTarget:  vous tes tr s marrants\n",
            "Epoch: 91  loss: 4.329760232940316\n",
            "\tOutput:  aije fait pr\n",
            "\tTarget:  aije bien capt\n",
            "Epoch: 92  loss: 4.332412086427212\n",
            "\tOutput:  vous es t le mon nez\n",
            "\tTarget:  tu m'as p t le nez\n",
            "Epoch: 93  loss: 4.309286992996931\n",
            "\tOutput:  vous tes d gueulasse r\n",
            "\tTarget:  vous tes d go tantes\n",
            "Epoch: 94  loss: 4.288216350600123\n",
            "\tOutput:  vous es important\n",
            "\tTarget:  tu es important\n",
            "Epoch: 95  loss: 4.300622269511223\n",
            "\tOutput:  vous tes tes <eos>\n",
            "\tTarget:  vous vous exprimez bien\n",
            "Epoch: 96  loss: 4.28414062410593\n",
            "\tOutput:  tout est <eos> compte\n",
            "\tTarget:  tout a son importance\n",
            "Epoch: 97  loss: 4.268977288156748\n",
            "\tOutput:  vous toutes qu'astu\n",
            "\tTarget:  avezvous bien dormi\n",
            "Epoch: 98  loss: 4.269168214872479\n",
            "\tOutput:  remplissez le ann\n",
            "\tTarget:  remplissez les blancs\n",
            "Epoch: 99  loss: 4.244105326011777\n",
            "\tOutput:  tu es matinal <eos> <eos>\n",
            "\tTarget:  tu es l t t\n",
            "Epoch: 100  loss: 4.224152905866504\n",
            "\tOutput:  connaistu du ais\n",
            "\tTarget:  parlestu fran ais\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw4oioTQmnXC",
        "colab_type": "text"
      },
      "source": [
        "# Test your translator\n",
        "\n",
        "##### Unless you speak french you're going have to check it with google translate https://translate.google.com/\n",
        "##### I found it started doing alright once the loss got below 10 but this might take a while"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42lq6wYrmnXC",
        "colab_type": "code",
        "outputId": "44ec6b32-d2d7-4623-b146-72006e6b595f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentence = 'have you had a good morning'\n",
        "translate(sentence)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'on dirait que tu es'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2Po6aqDmnXF",
        "colab_type": "text"
      },
      "source": [
        "#### Test it on testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjvmdMx3mnXF",
        "colab_type": "code",
        "outputId": "d61ebc20-867b-4a3b-cb09-1ec1d3be3ec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "model.eval()\n",
        "scores = []\n",
        "preds = []\n",
        "targetlist = []\n",
        "for j,(context, target) in enumerate(testloader):\n",
        "        trg_input = target[:,:-1]\n",
        "        targets = target[:,1:].contiguous().view(-1)\n",
        "        targetlist.append(targets)\n",
        "        src,trg = mask(context,trg_input)\n",
        "        output = model(context,trg_input,src,trg)\n",
        "        pred = F.softmax(output,2).argmax(2)\n",
        "        preds.append(pred.detach())\n",
        "        correct = sum(pred[0][targets!=fr_to_ix['<pad>']]==targets[targets!=fr_to_ix['<pad>']]).item()/len(targets[targets!=fr_to_ix['<pad>']])\n",
        "        scores.append(correct)\n",
        "plt.plot(scores)\n",
        "print('Average # of words correct',np.mean(scores))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average # of words correct 0.5982164502164502\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tgN-ed3mnXI",
        "colab_type": "text"
      },
      "source": [
        "# MULTI-HEAD ATTENTION (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hJQS00FmnXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class multi_attention(nn.Module):\n",
        "    def __init__(self,dim,encoder_dim,dropout = .1):\n",
        "        super().__init__()\n",
        "        \n",
        "        heads = []\n",
        "        for i in range(???): ### TODO ### CHOOSE THE # OF HEADS YOU WANT\n",
        "            heads.append(???) ### TODO ### ADD SELF_ATTENTION LAYERS TO HEADS\n",
        "        \n",
        "        self.heads = nn.ModuleList(heads)\n",
        "        \n",
        "        self.linear = nn.Linear(???,encoder_dim) ### TODO ###\n",
        "    \n",
        "    \n",
        "    def forward(self,x,mask=None):\n",
        "        headoutputs = [layer(x,mask) for layer in self.heads]\n",
        "        headoutputs = torch.cat(headoutputs,dim=2)\n",
        "        return self.linear(headoutputs)\n",
        "    \n",
        "class encoder(nn.Module):\n",
        "    def __init__(self,dim,enc_dim,vocab_size,dropout=.1):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.enc_dim = enc_dim\n",
        "        self.attention = multi_attention(dim,enc_dim,dropout)\n",
        "        self.norm1 = nn.LayerNorm(enc_dim)\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(enc_dim,enc_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.residual = nn.Linear(dim,enc_dim)\n",
        "        self.norm2 = nn.LayerNorm(enc_dim)\n",
        "    \n",
        "    def forward(self,x,mask):\n",
        "        z = self.attention(x,mask)\n",
        "        if self.dim != self.enc_dim:\n",
        "            x = self.residual(x)\n",
        "        z = self.norm1(x+z)\n",
        "        z2 = self.linear(z)\n",
        "        return self.norm2(z+z2)\n",
        "     \n",
        "    \n",
        "class decoder(nn.Module):\n",
        "    def __init__(self,dim,input_size,vocab_size,dropout=.1):\n",
        "        super().__init__()\n",
        "        self.attention = multi_attention(input_size,dim,dropout)\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.EDattention = encdec_attention(dim,dropout)\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(dim,dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.norm3 = nn.LayerNorm(dim)\n",
        "    \n",
        "    def forward(self,x,k,v,src,trg):\n",
        "        z = self.attention(x,trg)\n",
        "        z = self.norm1(z+x)\n",
        "        z2 = self.EDattention(z,k,v,src)\n",
        "        z2 = self.norm2(z2+z)\n",
        "        z3 = self.linear(z2)\n",
        "        return self.norm3(z3+z2)\n",
        "    \n",
        "class transformer(nn.Module):\n",
        "    def __init__(self,dim,encoder_dim,enc_vocab_size,dec_vocab_size,input_size):\n",
        "        super().__init__()\n",
        "        self.embedding1 = nn.Embedding(enc_vocab_size,dim)\n",
        "        self.embedding2 = nn.Embedding(dec_vocab_size,encoder_dim)\n",
        "        \n",
        "        self.pe1 = PositionalEncoder(dim,enmax)\n",
        "        self.pe2 = PositionalEncoder(encoder_dim,frmax)\n",
        "        self.encoders = []\n",
        "    \n",
        "        self.encoders.append(encoder(dim,encoder_dim,enc_vocab_size))   ### FEEL FREE TO ADD OR REMOVE ENCODERS\n",
        "        self.encoders = nn.ModuleList(self.encoders)\n",
        "        \n",
        "        self.decoders = []\n",
        "        self.decoders.append(decoder(encoder_dim,encoder_dim,dec_vocab_size)) ### FEEL FREE TO ADD OR REMOVE ENCODERS\n",
        "        self.decoders = nn.ModuleList(self.decoders)\n",
        "        \n",
        "        self.final = nn.Sequential(\n",
        "            nn.Linear(encoder_dim,dec_vocab_size),\n",
        "            nn.LogSoftmax(2)\n",
        "        )\n",
        "        \n",
        "        self.k = nn.Linear(encoder_dim,encoder_dim)\n",
        "        self.v = nn.Linear(encoder_dim,encoder_dim)\n",
        "        \n",
        "    def create_dec_KV(self,z):\n",
        "        K = self.k(z)\n",
        "        V = self.v(z)\n",
        "        return K,V\n",
        "    \n",
        "    def encode(self,x,src):\n",
        "        x = self.embedding1(x)\n",
        "        x = self.pe1(x)\n",
        "        for layer in self.encoders:\n",
        "            x = layer(x,src)\n",
        "        return x\n",
        "    \n",
        "    def decode(self,y,K,V,src,trg):\n",
        "        y = self.embedding2(y)\n",
        "        y = self.pe2(y)\n",
        "        for layer in self.decoders:\n",
        "            y = layer(y,K,V,src,trg)\n",
        "        return self.final(y)\n",
        "        \n",
        "    \n",
        "    def forward(self,x,y,src,trg):\n",
        "        x = self.encode(x,src)\n",
        "        K,V = self.create_dec_KV(x)\n",
        "        y = self.decode(y,K,V,src,trg)\n",
        "        \n",
        "        return y\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGMFsX2-mnXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = transformer(enmax,enmax,len(envocab),len(frvocab),frmax)\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhcXcB0DmnXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.01,weight_decay=.00001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,factor=.1,patience=10,threshold=1,min_lr=.0001)\n",
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElGw6aChmnXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(50):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for j,(context, target) in enumerate(trainloader):\n",
        "        trg_input = target[:,:-1]\n",
        "        outmask = target[:,1:]!= fr_to_ix['<pad>']\n",
        "        targets = target[:,1:].contiguous().view(-1)\n",
        "        src,trg = mask(context,trg_input)\n",
        "        output = model(context,trg_input,src,trg)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(output.view(output.shape[0]*output.shape[1],-1),targets)\n",
        "        loss.backward()\n",
        "        total_loss += loss.item()\n",
        "        optimizer.step()\n",
        "    scheduler.step(total_loss)\n",
        "    print('Epoch:', i+1,' loss:', total_loss)\n",
        "    model.eval()\n",
        "    scores = []\n",
        "    preds = []\n",
        "    targetlist = []\n",
        "    for j,(context, target) in enumerate(valloader):\n",
        "            trg_input = target[:,:-1]\n",
        "            targets = target.contiguous().view(-1)\n",
        "            targetlist.append(targets)\n",
        "            src,trg = mask(context,trg_input)\n",
        "            output = model(context,trg_input,src,trg)\n",
        "            pred = F.softmax(output,2).argmax(2)\n",
        "            preds.append(pred)\n",
        "            break\n",
        "    compareoutput(preds,targetlist,loc=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iF__oggvmnXU",
        "colab_type": "text"
      },
      "source": [
        "# Test your  multi-head transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PstlS2HgmnXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = 'how are you'\n",
        "translate(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ilwZtjkmnXX",
        "colab_type": "text"
      },
      "source": [
        "# QUESTION\n",
        "\n",
        "#### 1) Was the runtime of your multi-head transformer noticably longer than the single head one? What about the speed the loss decreased? If you had the time and resources to train it to a good spot, how did the translation quality compare to the single-headed transformer?\n",
        "\n",
        "#### 2)Try adding encoders and decoders to one of your transformers. Does having the extra layers improve performance? How does it affect runtime? \n",
        "The performance definitely got better with more layers. The runtime wasn't too awful on gpu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9g8Qj_KmnXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}